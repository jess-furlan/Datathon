import json
import os
from typing import Dict, Any, List, Tuple

import streamlit as st

# --- defensive import to aid debugging on Streamlit Cloud ---
try:
    import numpy as np
    import pandas as pd
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    from unidecode import unidecode
except ModuleNotFoundError as e:
    st.error(
        "DependÃªncias ausentes. Verifique se o requirements.txt estÃ¡ na RAIZ do repo e contÃ©m: "
        "streamlit, scikit-learn, pandas, numpy, unidecode. Depois limpe o cache no Manage app. "
        f"MÃ³dulo nÃ£o encontrado: {e}"
    )
    st.stop()

# =============================
# Helpers
# =============================

# Lista simples de stopwords PT (scikit-learn sÃ³ tem 'english' built-in)
PT_STOP_WORDS = [
    'a','Ã ','Ã s','ao','aos','as','o','os','um','uma','umas','uns',
    'de','do','da','dos','das','d','em','no','na','nos','nas','num','numa',
    'por','para','pra','pras','pro','pros','com','sem','sob','sobre','entre',
    'e','ou','mas','tambem','tambÃ©m','como','se','que','quem','quando','onde',
    'porque','porquÃª','por que','pois','ja','jÃ¡','mais','menos','muito','muita','muitos','muitas',
    'ser','estar','ter','haver','ir','vai','vai','foi','era','sao','sÃ£o','serao','serÃ£o','seria','seriam',
    'eu','tu','ele','ela','nos','nÃ³s','vos','vÃ³s','eles','elas','me','te','se','lhe','lhes','nosso','nossa','nossos','nossas',
    'isso','isto','aquilo','este','esta','esse','essa','aquele','aquela','estes','estas','esses','essas','aqueles','aquelas'
]

SENIORITY_ORDER = {
    'estagio': 0,
    'trainee': 0,
    'junior': 1,
    'jÃºnior': 1,
    'jr': 1,
    'pleno': 2,
    'mid': 2,
    'senior': 3,
    'sÃªnior': 3,
    'sr': 3,
    'especialista': 4,
    'lead': 4,
    'lider': 4,
    'lÃ­der': 4,
    'gerente': 5,
}

LANG_LEVEL_ORDER = {
    'nenhum': 0,
    'basico': 1,
    'bÃ¡sico': 1,
    'intermediario': 2,
    'intermediÃ¡rio': 2,
    'avancado': 3,
    'avanÃ§ado': 3,
    'fluente': 4,
    'nativo': 5
}

CONTRACT_TYPES = [
    'CLT', 'CLT Full', 'PJ', 'EstÃ¡gio', 'TemporÃ¡rio', 'Tempo Parcial', 'Freelancer', 'Cooperado'
]

LANGS = ['InglÃªs', 'Espanhol', 'Outro']


def norm_text(x: str) -> str:
    if not isinstance(x, str):
        return ''
    return unidecode(x.lower().strip())


def extract_lang_level(text: str) -> int:
    """Map arbitrary text to a language level order value."""
    t = norm_text(text)
    for k, v in LANG_LEVEL_ORDER.items():
        if k in t:
            return v
    # Try common abbreviations
    if t in {'a2', 'basic'}: return 1
    if t in {'b1', 'b2', 'intermediate'}: return 2
    if t in {'c1', 'advanced'}: return 3
    if t in {'c2', 'fluent', 'native'}: return 4
    return 0


def extract_seniority(text: str) -> int:
    t = norm_text(text)
    for k, v in SENIORITY_ORDER.items():
        if k in t:
            return v
    return 0


def jobs_json_to_df(jobs: Dict[str, Any]) -> pd.DataFrame:
    rows = []
    for job_id, job in jobs.items():
        info = job.get('informacoes_basicas', {})
        perfil = job.get('perfil_vaga', {})

        titulo = info.get('titulo_vaga', '')
        area = perfil.get('areas_atuacao', '')
        atividades = perfil.get('principais_atividades', '')
        competencias = perfil.get('competencia_tecnicas_e_comportamentais', '')
        cidade = perfil.get('cidade', '')
        estado = perfil.get('estado', '')
        pais = perfil.get('pais', '')
        nivel_prof = perfil.get('nivel profissional', perfil.get('nivel_profissional', ''))
        nivel_ingles = perfil.get('nivel_ingles', '')
        nivel_espanhol = perfil.get('nivel_espanhol', '')
        contrato = info.get('tipo_contratacao', '')

        bag_text = ' \n '.join([
            str(titulo), str(area), str(atividades), str(competencias)
        ])

        rows.append({
            'job_id': job_id,
            'titulo': titulo,
            'area': area,
            'atividades': atividades,
            'competencias': competencias,
            'cidade': cidade,
            'estado': estado,
            'pais': pais,
            'nivel_prof': nivel_prof,
            'ingles_req': nivel_ingles,
            'espanhol_req': nivel_espanhol,
            'contrato': contrato,
            'bag_text': bag_text
        })
    df = pd.DataFrame(rows)
    return df


@st.cache_data(show_spinner=False)
def load_jobs(json_file: str) -> pd.DataFrame:
    with open(json_file, 'r', encoding='utf-8') as f:
        jobs = json.load(f)
    return jobs_json_to_df(jobs)

# PersistÃªncia simples: base de candidatos
def save_candidate_record(record: Dict[str, Any], path: str = 'data/candidatos.csv') -> str:
    os.makedirs(os.path.dirname(path), exist_ok=True)
    df_row = pd.DataFrame([record])
    if os.path.exists(path):
        df_row.to_csv(path, mode='a', header=False, index=False)
    else:
        df_row.to_csv(path, index=False)
    return path

@st.cache_resource(show_spinner=False)
def build_vectorizer(corpus: List[str]) -> Tuple[TfidfVectorizer, np.ndarray]:
    vect = TfidfVectorizer(stop_words=PT_STOP_WORDS, min_df=1, max_df=0.9, ngram_range=(1, 2))
    X = vect.fit_transform([norm_text(c) for c in corpus])
    return vect, X


def text_similarity_score(vect: TfidfVectorizer, X_jobs, candidate_text: str) -> np.ndarray:
    q = vect.transform([norm_text(candidate_text)])
    sims = cosine_similarity(q, X_jobs)[0]
    return sims


def level_match_score(req: str, got: str) -> float:
    if not req:
        return 1.0  # no requirement
    return min(1.0, extract_lang_level(got) / max(1, extract_lang_level(req)))


def seniority_match_score(req: str, got: str) -> float:
    r = extract_seniority(req)
    g = extract_seniority(got)
    if r == 0:
        return 1.0
    # If candidate is above requirement, cap at 1
    return min(1.0, g / max(1, r))


def location_match_score(row: pd.Series, cand_estado: str, cand_cidade: str) -> float:
    if not row.get('estado') and not row.get('cidade'):
        return 1.0
    s = 0.0
    if cand_estado and norm_text(cand_estado) == norm_text(str(row.get('estado', ''))):
        s += 0.6
    if cand_cidade and norm_text(cand_cidade) == norm_text(str(row.get('cidade', ''))):
        s += 0.4
    return s if s > 0 else 0.2  # pequena benevolÃªncia


def contract_match_score(req: str, got: str) -> float:
    if not req:
        return 1.0
    return 1.0 if norm_text(req) in norm_text(got) or norm_text(got) in norm_text(req) else 0.6


def compute_scores(df: pd.DataFrame, vect: TfidfVectorizer, X_jobs, *,
                   cand_text: str,
                   cand_senior: str,
                   cand_ingles: str,
                   cand_espanhol: str,
                   cand_estado: str,
                   cand_cidade: str,
                   cand_contrato: str,
                   weights: Dict[str, float]) -> pd.DataFrame:

    sims = text_similarity_score(vect, X_jobs, cand_text)

    s_sen = df.apply(lambda r: seniority_match_score(r['nivel_prof'], cand_senior), axis=1).values
    s_en = df.apply(lambda r: level_match_score(r['ingles_req'], cand_ingles), axis=1).values
    s_es = df.apply(lambda r: level_match_score(r['espanhol_req'], cand_espanhol), axis=1).values
    s_loc = df.apply(lambda r: location_match_score(r, cand_estado, cand_cidade), axis=1).values
    s_ctr = df.apply(lambda r: contract_match_score(r['contrato'], cand_contrato), axis=1).values

    # Normalize non-text components into [0,1]
    # Already in [0,1], except location that may be 0.2-1
    s_loc = np.clip(s_loc, 0, 1)

    w = weights
    final = (
        w['texto'] * sims +
        w['senioridade'] * s_sen +
        w['ingles'] * s_en +
        w['espanhol'] * s_es +
        w['local'] * s_loc +
        w['contrato'] * s_ctr
    )

    out = df.copy()
    out['score_texto'] = sims
    out['score_senioridade'] = s_sen
    out['score_ingles'] = s_en
    out['score_espanhol'] = s_es
    out['score_local'] = s_loc
    out['score_contrato'] = s_ctr
    out['score_final'] = final

    return out.sort_values('score_final', ascending=False)


# =============================
# UI
# =============================

st.set_page_config(page_title='Roteirizador de Entrevistas â€¢ Match de Vagas', layout='wide')
st.title('ðŸŽ¯ Roteirizador de Entrevistas â€” Match de Vagas')

with st.sidebar:
    st.header('âš™ï¸ Dados de Vagas')
    st.caption('O arquivo **deve se chamar exatamente** `vagas.json`.')
    upload = st.file_uploader('Envie o arquivo vagas.json (JSON)', type=['json'])
    default_path = 'vagas.json'
    df_jobs = None
    if upload is not None:
        if upload.name != 'vagas.json':
            st.error('O arquivo enviado deve se chamar **vagas.json**. Renomeie e envie novamente.')
            st.stop()
        jobs = json.load(upload)
        df_jobs = jobs_json_to_df(jobs)
    elif os.path.exists(default_path):
        st.caption('Usando vagas.json encontrado no diretÃ³rio do app.')
        df_jobs = load_jobs(default_path)
    else:
        st.info('Envie o arquivo **vagas.json** no formato esperado.')

    st.divider()
    st.subheader('ðŸ”§ Pesos do Match')
    colw1, colw2 = st.columns(2)
    with colw1:
        w_text = st.slider('Peso â€” Similaridade de Texto', 0.0, 1.0, 0.55, 0.05)
        w_sen = st.slider('Peso â€” Senioridade', 0.0, 1.0, 0.15, 0.05)
        w_loc = st.slider('Peso â€” LocalizaÃ§Ã£o', 0.0, 1.0, 0.10, 0.05)
    with colw2:
        w_en = st.slider('Peso â€” InglÃªs', 0.0, 1.0, 0.08, 0.02)
        w_es = st.slider('Peso â€” Espanhol', 0.0, 1.0, 0.05, 0.02)
        w_ctr = st.slider('Peso â€” Tipo de Contrato', 0.0, 1.0, 0.07, 0.02)
    # Normalize weights to sum 1
    total_w = w_text + w_sen + w_loc + w_en + w_es + w_ctr
    weights = {
        'texto': w_text/total_w,
        'senioridade': w_sen/total_w,
        'local': w_loc/total_w,
        'ingles': w_en/total_w,
        'espanhol': w_es/total_w,
        'contrato': w_ctr/total_w
    }

    st.subheader('ðŸŽšï¸ Limiar de Match')
    match_threshold = st.slider('PontuaÃ§Ã£o mÃ­nima', 0.0, 1.0, 0.35, 0.01)

    # BotÃ£o de recÃ¡lculo independente do form
    recalc = st.button('ðŸ” Recalcular matches')


st.subheader('ðŸ“ FormulÃ¡rio do Entrevistador')
with st.form('form_candidato'):
    c1, c2, c3 = st.columns(3)
    with c1:
        cand_nome = st.text_input('Nome do candidato (opcional)')
        cand_estado = st.text_input('Estado (UF) do candidato')
        cand_cidade = st.text_input('Cidade do candidato')
    with c2:
        cand_senior = st.selectbox('Senioridade do candidato', [
            'JÃºnior', 'Pleno', 'SÃªnior', 'Especialista / LÃ­der', 'Gerente', 'Outro'
        ], index=1)
        cand_contrato = st.selectbox('PreferÃªncia de contrato', CONTRACT_TYPES, index=0)
        cand_disp = st.text_input('Disponibilidade/Inicio (livre)')
    with c3:
        cand_ingles = st.selectbox('InglÃªs', ['Nenhum', 'BÃ¡sico', 'IntermediÃ¡rio', 'AvanÃ§ado', 'Fluente', 'Nativo'], index=2)
        cand_espanhol = st.selectbox('Espanhol', ['Nenhum', 'BÃ¡sico', 'IntermediÃ¡rio', 'AvanÃ§ado', 'Fluente', 'Nativo'], index=0)
        top_k = st.slider('Quantos matches retornar?', min_value=3, max_value=30, value=10, step=1)

    cand_skills = st.text_area('Resumo tÃ©cnico do candidato (stack, ferramentas, certificaÃ§Ãµes, experiÃªncias relevantes)', height=150, placeholder='Ex.: AWS, SAP BASIS, SQL, Oracle, gestÃ£o de incidentes, ITIL, lideranÃ§a de times, negociaÃ§Ã£o...')
    cand_obj = st.text_area('Objetivo / Ã¡reas de interesse (opcional)', height=80)

    submitted = st.form_submit_button('ðŸ”Ž Buscar matches')

trigger = submitted or ('recalc' in locals() and recalc)
if trigger:
    if df_jobs is None or df_jobs.empty:
        st.error('Nenhum arquivo de vagas carregado. Envie o **vagas.json** no menu lateral.')
        st.stop()

    with st.spinner('Calculando matches...'):
        # Build corpus & vectorizer
        vect, X_jobs = build_vectorizer(df_jobs['bag_text'].fillna('').tolist())

        cand_text = ' '.join([
            cand_senior,
            f"InglÃªs: {cand_ingles}", f"Espanhol: {cand_espanhol}",
            cand_skills, cand_obj
        ])

        scored = compute_scores(
            df_jobs, vect, X_jobs,
            cand_text=cand_text,
            cand_senior=cand_senior,
            cand_ingles=cand_ingles,
            cand_espanhol=cand_espanhol,
            cand_estado=cand_estado,
            cand_cidade=cand_cidade,
            cand_contrato=cand_contrato,
            weights=weights
        )

        # Filtrar por limiar de match
        matches = scored[scored['score_final'] >= match_threshold].copy()

    # auditoria dos pesos usados
    st.caption(
        f"Pesos usados â†’ Texto: {weights['texto']:.2f} â€¢ Senioridade: {weights['senioridade']:.2f} â€¢ "
        f"InglÃªs: {weights['ingles']:.2f} â€¢ Espanhol: {weights['espanhol']:.2f} â€¢ "
        f"Local: {weights['local']:.2f} â€¢ Contrato: {weights['contrato']:.2f}"
    )

    if matches.empty:
        # Salva candidato para futuras oportunidades
        rec = {
            'timestamp': pd.Timestamp.now().isoformat(),
            'nome': cand_nome,
            'estado': cand_estado,
            'cidade': cand_cidade,
            'senioridade': cand_senior,
            'ingles': cand_ingles,
            'espanhol': cand_espanhol,
            'contrato': cand_contrato,
            'skills': cand_skills,
            'objetivo': cand_obj,
            'obs': 'Sem vagas compatÃ­veis no momento'
        }
        path_saved = save_candidate_record(rec)
        st.warning('NÃ£o hÃ¡ vagas compatÃ­veis com o perfil informado (acima do limiar). Os dados do candidato foram armazenados na **base de candidatos** para futuras oportunidades.')
        st.caption(f'Base de candidatos: {path_saved}')
        st.stop()

    st.success(f"{len(matches)} vagas compatÃ­veis (limiar {match_threshold:.2f}). Exibindo top {top_k}.")

    cols = ['job_id', 'titulo', 'area', 'cidade', 'estado', 'nivel_prof', 'ingles_req', 'espanhol_req', 'contrato', 'score_final']
    st.dataframe(matches[cols].head(top_k).style.format({'score_final': '{:.3f}'}), use_container_width=True)

    st.divider()
    st.subheader('ðŸ”Ž Detalhamento por vaga (top resultados)')

    # GrÃ¡fico de decomposiÃ§Ã£o de score para top-5
    import matplotlib.pyplot as plt

    for _, row in matches.head(min(5, len(matches))).iterrows():
        with st.expander(f"{row['job_id']} â€” {row['titulo']}  â€¢  Score: {row['score_final']:.3f}"):
            cA, cB = st.columns([2,1])
            with cA:
                st.markdown('**Principais atividades**')
                st.write(row.get('atividades', ''))
                st.markdown('**CompetÃªncias**')
                st.write(row.get('competencias', ''))
            with cB:
                st.markdown('**Match breakdown**')
                st.metric('Texto', f"{row['score_texto']:.3f}")
                st.metric('Senioridade', f"{row['score_senioridade']:.3f}")
                st.metric('InglÃªs', f"{row['score_ingles']:.3f}")
                st.metric('Espanhol', f"{row['score_espanhol']:.3f}")
                st.metric('LocalizaÃ§Ã£o', f"{row['score_local']:.3f}")
                st.metric('Contrato', f"{row['score_contrato']:.3f}")

            # chart
            labels = ['Texto','Senioridade','InglÃªs','Espanhol','Local','Contrato']
            values = [
                float(row['score_texto']),
                float(row['score_senioridade']),
                float(row['score_ingles']),
                float(row['score_espanhol']),
                float(row['score_local']),
                float(row['score_contrato'])
            ]
            fig, ax = plt.subplots()
            ax.bar(labels, values)
            ax.set_ylim(0, 1)
            ax.set_ylabel('Score (0-1)')
            ax.set_title('DecomposiÃ§Ã£o de Score')
            st.pyplot(fig)
else:
    st.info('Preencha o formulÃ¡rio e clique em **Buscar matches** ou use **Recalcular matches** no menu lateral.')

